{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('pytorch': conda)"
  },
  "interpreter": {
   "hash": "c2c0bba31bef276960c92166e4dc324d20d321691368e020af08fea8957d0a65"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "import yaml\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToPILImage, ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.optim import Adam\n",
    "from torchvision.utils import save_image\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import sys\n",
    "sys.path.append(\"models\")\n",
    "\n",
    "import models\n",
    "import utils\n",
    "from utils import make_coord,set_save_path,ssim\n",
    "import datasets\n",
    "from test import eval_psnr,batched_predict\n",
    "\n",
    "from models import losses\n",
    "from models.liif import LIIF\n",
    "from models.discriminator import Discriminator\n",
    "from models.losses import AdversarialLoss\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = r'weights\\edsr-baseline-liif.pth'\n",
    "lr_path = r'testimg\\div2klrx4\\0801x4.png'\n",
    "hr_path = r'load\\div2k\\DIV2K_valid_HR\\0801.png'\n",
    "sr_path = r'testimg\\ouput.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ToTensor()(Image.open(lr_path))\n",
    "hr = ToTensor()(Image.open(hr_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.make(torch.load(modelpath)['model'], load_sd=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = lr.shape[1]*2, lr.shape[2]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = make_coord((h, w)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = torch.ones_like(coord)\n",
    "cell[:, 0] *= 2 / h\n",
    "cell[:, 1] *= 2 / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ((lr - 0.5) / 0.5).cuda().unsqueeze(0)\n",
    "coord = coord.unsqueeze(0)\n",
    "cell = cell.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = batched_predict(model, lr, coord, cell, bsize=30000)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = (sr * 0.5 + 0.5).clamp(0, 1).view(h, w, 3).permute(2, 0, 1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToPILImage()(sr).save(sr_path)\n",
    "plt.imshow(ToPILImage()(sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim(hr.unsqueeze(0),sr.unsqueeze(0))"
   ]
  },
  {
   "source": [
    "# 单步"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    feat = model.gen_feat(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(feat.shape[1]):\n",
    "    featimg= ToPILImage()(feat[0][i])\n",
    "    featimg.save(f\"feat/featx{i}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuf = F.unfold(feat, 3, padding=1).view(feat.shape[0], feat.shape[1] * 9, feat.shape[2], feat.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(featuf.shape[1]):\n",
    "    featimg= ToPILImage()(featuf[0][i])\n",
    "    featimg.save(f\"featunfold/featuf{i}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "areas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx_lst = [-1, 1]\n",
    "vy_lst = [-1, 1]\n",
    "eps_shift = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx = 2 / featuf.shape[-2] / 2  #2/LR_H/2\n",
    "ry = 2 / featuf.shape[-1] / 2  #2/LR_W/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_coord = make_coord(featuf.shape[-2:], flatten=False).cuda()\n",
    "#[LR_H,LR_W,2]\n",
    "feat_coord.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_coord = feat_coord.permute(2, 0, 1).unsqueeze(0).expand(featuf.shape[0], 2, *featuf.shape[-2:])\n",
    "#[N,2,LR_H,LR_W]\n",
    "feat_coord.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx = -1\n",
    "vy = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = coord[:, 0: 1000, :]\n",
    "cell = cell[:, 0: 1000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_ = coord.clone()#[N,SR_H*SR_W,2]\n",
    "coord_[:, :, 0] += vx * rx + eps_shift\n",
    "coord_[:, :, 1] += vy * ry + eps_shift\n",
    "coord_.clamp_(-1 + 1e-6, 1 - 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_ = coord_.flip(-1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_feat = F.grid_sample(featuf, coord_, mode='nearest', align_corners=False)\n",
    "#[N,C*9,1,SR_H*SR_W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_feat = q_feat[:, :, 0, :].permute(0, 2, 1)#[N,SR_H*SR_W,C*9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_coord = F.grid_sample(feat_coord, coord_, mode='nearest', align_corners=False)\n",
    "#[N,2,1,SR_H*SR_W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_coord = q_coord[:, :, 0, :].permute(0, 2, 1)#[N,SR_H*SR_W,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_coord = coord - q_coord #[N,SR_H*SR_W,2]\n",
    "rel_coord[:, :, 0] *= featuf.shape[-2]\n",
    "rel_coord[:, :, 1] *= featuf.shape[-1]\n",
    "inp = torch.cat([q_feat, rel_coord], dim=-1) #[N,SR_H*SR_W,C*9+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_cell = cell.clone()\n",
    "rel_cell[:, :, 0] *= feat.shape[-2]\n",
    "rel_cell[:, :, 1] *= feat.shape[-1]\n",
    "inp = torch.cat([inp, rel_cell], dim=-1) #[N,SR_H*SR_W,C*9+2+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.imnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, q = coord.shape[:2] #bs=N q=SR_H*SR_W\n",
    "#[N*SR_H*SR_W,C*9+2+2] --> [N*SR_H*SR_W,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.imnet(inp.view(bs * q, -1)).view(bs, q, -1) #[N,SR_H*SR_W,3]\n",
    "preds.append(pred) #[[N,SR_H*SR_W],[N,SR_H*SR_W],[N,SR_H*SR_W],[N,SR_H*SR_W]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = torch.abs(rel_coord[:, :, 0] * rel_coord[:, :, 1])\n",
    "areas.append(area + 1e-9) #[[N,SR_H*SR_W],[N,SR_H*SR_W],[N,SR_H*SR_W],[N,SR_H*SR_W]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_area = torch.stack(areas).sum(dim=0) #[N,SR_H*SR_W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predimg = (ret * 0.5 + 0.5).clamp(0, 1).view(1000, 1, 3).permute(2, 0, 1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.ToPILImage()(predimg).save(\"1000x1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if self.local_ensemble:\n",
    "    t = areas[0]; areas[0] = areas[3]; areas[3] = t #swap(areas[0],areas[3])\n",
    "    t = areas[1]; areas[1] = areas[2]; areas[2] = t #swap(areas[1],areas[2])\n",
    "ret = 0\n",
    "for pred, area in zip(preds, areas):\n",
    "    ret = ret + pred * (area / tot_area).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = F.grid_sample(featuf, coord.flip(-1).unsqueeze(1), mode='nearest', align_corners=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = ret[:, :, 0, :].permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = ret.permute(0, 2, 1).view(1,576,h,w).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ret.shape[0]):\n",
    "    ToPILImage()(ret[i]).save(f\"grid_sample/g_{i}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "areas = []\n",
    "for vx in vx_lst:\n",
    "    for vy in vy_lst:\n",
    "        coord_ = coord.clone()#[N,SR_H*SR_W,2]\n",
    "        coord_[:, :, 0] += vx * rx + eps_shift\n",
    "        coord_[:, :, 1] += vy * ry + eps_shift\n",
    "        coord_.clamp_(-1 + 1e-6, 1 - 1e-6)\n",
    "        coord_ = coord_.flip(-1).unsqueeze(1)\n",
    "        q_feat = F.grid_sample(featuf, coord_, mode='nearest', align_corners=False)\n",
    "        #[N,C*9,1,SR_H*SR_W]\n",
    "        q_feat = q_feat[:, :, 0, :].permute(0, 2, 1)#[N,SR_H*SR_W,C*9]\n",
    "        q_coord = F.grid_sample(feat_coord, coord_, mode='nearest', align_corners=False)\n",
    "        #[N,2,1,SR_H*SR_W]\n",
    "        q_coord = q_coord[:, :, 0, :].permute(0, 2, 1)#[N,SR_H*SR_W,2]\n",
    "\n",
    "        rel_coord = coord - q_coord #[N,SR_H*SR_W,2]\n",
    "        rel_coord[:, :, 0] *= feat.shape[-2]\n",
    "        rel_coord[:, :, 1] *= feat.shape[-1]\n",
    "        inp = torch.cat([q_feat, rel_coord], dim=-1) #[N,SR_H*SR_W,C*9+2]\n",
    "\n",
    "        rel_cell = cell.clone()\n",
    "        rel_cell[:, :, 0] *= feat.shape[-2]\n",
    "        rel_cell[:, :, 1] *= feat.shape[-1]\n",
    "        inp = torch.cat([inp, rel_cell], dim=-1) #[N,SR_H*SR_W,C*9+2+2]\n",
    "\n",
    "        bs, q = coord.shape[:2] #bs=N q=SR_H*SR_W\n",
    "        #[N*SR_H*SR_W,C*9+2+2] --> [N*SR_H*SR_W,3]\n",
    "        pred = model.imnet(inp.view(bs * q, -1)).view(bs, q, -1) #[N,SR_H*SR_W,3]\n",
    "        preds.append(pred) #[[N,SR_H*SR_W],[N,SR_H*SR_W],[N,SR_H*SR_W],[N,SR_H*SR_W]]\n",
    "\n",
    "        area = torch.abs(rel_coord[:, :, 0] * rel_coord[:, :, 1])\n",
    "        areas.append(area + 1e-9) #[[N,SR_H*SR_W],[N,SR_H*SR_W],[N,SR_H*SR_W],[N,SR_H*SR_W]]\n",
    "\n",
    "tot_area = torch.stack(areas).sum(dim=0) #[N,SR_H*SR_W]\n",
    "\n",
    "t = areas[0]; areas[0] = areas[3]; areas[3] = t #swap(areas[0],areas[3])\n",
    "t = areas[1]; areas[1] = areas[2]; areas[2] = t #swap(areas[1],areas[2])\n",
    "ret = 0\n",
    "for pred, area in zip(preds, areas):\n",
    "    ret = ret + pred * (area / tot_area).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r'save\\ITCVD_drsenmkcax2\\epoch-best.pth'\n",
    "lr_path = r'E:\\Code\\Python\\datas\\RS\\ITCVD_patch\\ITCVD_test_patchx2\\007_0_0x2.jpg'\n",
    "hr_path = r'E:\\Code\\Python\\datas\\RS\\ITCVD_patch\\ITCVD_test_patch\\007_0_0.jpg'\n",
    "sr_path = r'testimg\\007_0_0x2x2.jpg'\n",
    "scale = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_x import batched_predict\n",
    "from models.losses import EdgeLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(lr_path)\n",
    "#img = transforms.Resize((int(img.height/2),int(img.width/2)),Image.BICUBIC)(img)\n",
    "timg = transforms.ToTensor()(img) #[3,LR_H,LR_W]\n",
    "model = models.make(torch.load(model_path)['model'], load_sd=True).cuda()\n",
    "bimg = ((timg - 0.5) / 0.5).cuda().unsqueeze(0)\n",
    "pred = batched_predict(model, bimg)[0] #[1,SR_H*SR_W,3]\n",
    "pred = (pred * 0.5 + 0.5).clamp(0, 1).cpu()\n",
    "transforms.ToPILImage()(pred).save(sr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        k = torch.Tensor([[.05, .25, .4, .25, .05]])\n",
    "        self.kernel = torch.matmul(k.t(), k).unsqueeze(0).repeat(3, 1, 1, 1)\n",
    "        if torch.cuda.is_available():\n",
    "            self.kernel = self.kernel.cuda()\n",
    "\n",
    "\n",
    "    def conv_gauss(self, img):\n",
    "        n_channels, _, kw, kh = self.kernel.shape\n",
    "        img = F.pad(img, (kw//2, kh//2, kw//2, kh//2), mode='replicate')\n",
    "        return F.conv2d(img, self.kernel, groups=n_channels)\n",
    "\n",
    "    def laplacian_kernel(self, current):\n",
    "        filtered = self.conv_gauss(current)     # filter\n",
    "        down = filtered[:, :, ::2, ::2]         # downsample\n",
    "        new_filter = torch.zeros_like(filtered)\n",
    "        new_filter[:, :, ::2, ::2] = down*4     # upsample\n",
    "        filtered = self.conv_gauss(new_filter)  # filter\n",
    "        diff = current - filtered\n",
    "        return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge =EdgeConv().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgemap = edge.laplacian_kernel(pred.unsqueeze(0).cuda())\n",
    "transforms.ToPILImage()(edgemap[0]).save('edgemap.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(r'load\\div2k\\DIV2K_valid_LR_bicubic\\X2\\0802x2.png')\n",
    "#img = transforms.Resize((int(img.height/2),int(img.width/2)),Image.BICUBIC)(img)\n",
    "timg = transforms.ToTensor()(img) #[3,LR_H,LR_W]\n",
    "edgemap = edge.laplacian_kernel(timg.unsqueeze(0).cuda())\n",
    "transforms.ToPILImage()(edgemap[0]).save('0802x2edge.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}